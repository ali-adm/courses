Краткое описание категорий в web-интерфейсе.

Agents — отвечают на вопросы, используя LLM или другие подключенные к ним инструменты.

Cashe — можно закешировать ответ LLM с использованием Redis, Momento, Upstash или использовать встроенный кеш.

Chains — цепочки, позволяют объединять несколько LLM и/или других запросов. В чатфлоу обязательно должна быть или цепочка, или агент.

Chat models — чат-модели, к которым вы можете подключиться.

Document loaders — загрузить данные из *.csv, *.json, Notion, Figma, Confluence и других источников.

Embeddings — разбиение текста запроса пользователя на части (вложения), LLM использует эти вложения, чтобы искать похожую информацию в своей базе данных и формировать ответ.

LLMs — сами языковые модели.

Memory — память, чтобы хранить беседы.

Moderation — проверка текста перед отправкой в LLM.

Output Parsers — ответ LLM может быть представлен в виде json или csv.

Prompts — инструкции для LLM.

Retrievers — возможность подключить дополнительные базы данных, например - с документами компании.

Text Splitters — возможность разделить предоставленные модели тексты на части по разным признакам.

Tools — возможность добавить готовый инструмент или создать свой.

Utilicies — набор простых утилит вроде калькулятора и подобных.

Vector Stores — подключение векторных баз данных.


Уроки по Flowise

https://youtu.be/kAyKOsm8L5Y
Урок FlowiseAI #2 - Создание Нашего Первого Chatflow (Цепочка LLM)

00:00 Создание первого потока чата

• Создание нового потока чата и сохранение его с названием. (Chatflows => +Add New => Значек дискеты в правом верхнем углу)
• Добавление кнопки конечной точки API для интеграции с внешними приложениями. (Значек </> в левом верхнем углу)

02:18 Добавление узлов в поток чата

• Добавление цепочки LLM для ввода и вывода. (Кнопка (+) справа => Chains => LLM Chain)
• Подключение узла OpenAI к цепочке. (Кнопка (+) справа => LLMs => OpenAI)
• Настройка модели искусственного интеллекта и температуры. (Узел OpenAI => Model name GPT-3.5-Turbo-instruct и Temperature - 0,7, 0 - строгие ответы, 1 - креативные ответы; Connect Credential - API key)

06:39 Добавление шаблона приглашения

• Добавление шаблона приглашения для указания входных данных и ожидаемых выходных данных. (Кнопка (+) => Prompts => Prompt Template)
В тесте шаблона промпта в фигурных скобках можно указывать динамические значения или переменные. Например можно сопоставить динамическое значение с окном ввода чата, в промпте указать "Расскажи мне шутку про {subject}", далее открыв Format Prompt Values, напротив значения subject нажать на зеленую кнопку, и нажав в появившемся поле - выбрать question. После этих манипуляций чат будет шутить на заданную тему.
• Сохранение и тестирование потока чата.
Тестировать можно тут-же - справа кнопка чата.


https://youtu.be/yLfiNnK4NOM
Объединение нескольких цепочек (Быстрое создание цепочки) - Учебное пособие по FlowiseAI #3

Можно связать несколько цепочек вместе, взять выходные данные одной цепочки, и поместить их во входные данные другой.

00:00 Создание цепочки шеф-повара

• Создание цепочки, которая будет генерировать уникальный рецепт на основе основного ингредиента, предоставленного пользователем.
• Присвоение имени цепочке шеф-повар - chef и изменение шаблона приглашения. (Изменение предыдущего промпта, см. "Добавление шаблона приглашения" - Урок #2).

Потоки данных идут слева-направо. Пользовательский ввод (Prompt Template) и выходные данные узла OpenAI цепочки (LLM Chain) шеф-повара (chef) - передаются в правую часть холста на вход следующей цепочке критиков (critic).

01:40 Передача результатов цепочки шеф-повара в цепочку критиков

• Создание цепочки критиков, которая будет писать отзыв о рецепте. (см. "Добавление цепочки LLM - LLM Chain", "Подключение узла OpenAI" и "Добавление шаблона приглашения - Prompt Template" - Урок #2; В Prompt Template - промпт "Ты кулинарный критик, напиши отзыв о следующем рецепте: {recipe}.)
• Подключение цепочки шеф-повара к цепочке критиков и передача результатов в шаблон приглашения. (В LLM Chain шеф-повара chef, внизу параметр LLM Chain сменить на "Out Prediction", соединить LLM Chain шеф-повара с Prompt Template критика. Далее открыв Format Prompt Values, напротив значения recipe - повторить действия, описанные в Уроке #2, в конце, вместо question выбрать chef)

05:14 Использование более мощной модели для улучшения качества вывода

• Замена модели llm на модель чата и добавление модели открытого искусственного интеллекта для чата. (Удалить узел OpenAI цепочки критика critic, добавить новую модель чата - Кнопка (+) => Chat Models => ChatOpenAI)
• Установка учетных данных и температуры для модели gpt-3.5 turbo. (Настройка модели происходит так-же как в Главе #2, только Model Name - выбрать GPT-3.4-Turbo-1106)
• Проверка результатов с использованием новой модели и сравнение качества вывода. (Полностью, весь сгенерированный текст - можно посмотреть из консоли).


https://youtu.be/bT308854-Qw
Ускоренный курс FlowiseAI #4 - Анализаторы вывода и функция IfElse

00:00 Анализаторы выходных данных

• В этом видео автор объясняет, как использовать анализаторы выходных данных для получения структурированных данных из моделей искусственного интеллекта.
Используется стандартный набор: LLM Chain, nod OpenAI и шаблон промпта (Prompt Template), промптом используется следующее выражение: “Определи является ли следующее предложение истинным, или ложным. {sentence}”
• Он демонстрирует, как использовать анализаторы для извлечения информации из предложений и преобразования их в логические значения.
К набору добавляется анализатор структурированных ВД (+) => Output Parsers=>Structured Output Parser, и подключается ко входу Output Parser в LLM Chain. В анализаторе данных, нажав Additional Parameters, удалив предыдущие, добавить новый элемент, дать ему название в столбце Property — sentiment (чувства), для этого типа у нас есть возможность задать строку, число или логическое значение, задать логическое значение boolean, дать описание description “Истинно или ложно”

01:57 Примеры использования анализаторов

• Автор показывает, как использовать анализаторы для извлечения информации из предложений, таких как имя, возраст и фамилия супруга.
• Он также демонстрирует, как использовать анализаторы для условного вызова различных цепочек на основе результатов анализа.

08:10 Условный вызов цепочек

• Автор объясняет, как использовать анализаторы для преобразования ответов в логические значения и условного вызова различных цепочек на основе этих значений.
• Он показывает, как использовать эти анализаторы для работы с положительными и отрицательными отзывами и для передачи этих данных в другие цепочки.

12:15 Использование анализатора выходных данных

• В видео объясняется, как использовать анализатор выходных данных для обработки данных, полученных от модели.
• Анализатор позволяет определить, является ли ответ положительным или отрицательным, и на основе этого вызвать соответствующие цепочки.

13:13 Условный вызов цепочек

• В видео демонстрируется, как использовать функцию if-else для условного вызова цепочек на основе входных данных.
• В примере, если ответ положительный, вызывается положительная цепочка, в противном случае вызывается отрицательная цепочка.

15:25 Проверка работы анализатора

• В конце видео демонстрируется, как работает анализатор на примере.
• Ввод "еда была потрясающей" приводит к ответу "позитив", а ввод "официант был груб" приводит к ответу "извините, мы хотели бы связаться с вами".



Урок FlowiseAI #5 - Создайте чат-бота с цепочками разговоров и долговременной памятью

00:00 Создание чат-бота с использованием потокового искусственного интеллекта

• Создание нового потока общения в чате и сохранение его с названием.
• Добавление модели чата и подключение ее к цепочке.
Главное различие между LLM Chain и Conversation Chain - наличие памяти. Conversation Chain способна запоминать историю разговоров, и следовательно запоминать информацию.
• Добавление узла памяти и настройка его параметров.

03:27 Использование шаблонов приглашений и цепочек подсказок

• Добавление шаблона приглашения в чат и настройка его параметров.
• Использование готовых шаблонов из OpenAI для создания цепочек подсказок.
(+) => Prompts => Chat Prompt Template => Langchain Hub - много разных шаблонов с поиском. К Chat Prompt Template можно подключать LLM Chain для с дополнительным шаблоном приглашений и промптом. Примпер в Conversaltion Chatbot 1.

08:02 Модерация входных данных и долговременная память

• Использование узла быстрой модерации для цензуры нежелательных сообщений.
(+) => Moderation => Simple Prompt Moderation
• Использование узла модерации с OpenAI для блокировки нежелательных фраз.
(+) => Moderation => OpenAI Moderation
• Настройка долговременной памяти для хранения истории разговоров и их извлечения.
(+) => Memory => Uptrash Redis-Backed Chat Memory
• Настройка учетных данных для обновления и предоставление токена для базы данных.
(+) => 

11:42 Создание чат-бота с использованием технологии Flow Wise

• В видео рассказывается о создании чат-бота с использованием технологии Flow Wise.
• Сначала создается узел, который запоминает имя пользователя и его имя.
• Затем этот узел записывается в постоянную базу данных, что позволяет ему запоминать информацию даже после завершения разговора.
• В примере демонстрируется, как можно переключаться между двумя разговорами, используя разные идентификаторы сеанса.
• В конце видео демонстрируется, как можно использовать Flow Wise для создания чат-бота, который может запоминать информацию и отвечать на вопросы.



Учебное пособие FlowiseAI #6 - Общайтесь в чате с Вашими собственными данными, используя цепочки поиска (PDF и Web Scraper)

00:00 Создание поискового чат-бота

• Создание чат-бота, способного отвечать на вопросы из собственных источников данных, таких как PDF-документы, веб-сайты и базы данных.
• Использование технологии "расширенной генерации поиска" для улучшения ответов чат-бота.

02:58 Создание векторного хранилища

• Подключение потока чата к источнику данных (веб-сайт, PDF-документ и т.д.).
К:
(+) Chains => Conversational Retrieval QA Chain 
Подключить:
(+) Chat Models => ChatOpenAI 
(+) Vector Stores => In-Memory Vector Store
К In-Memory Vector Store подключить:
(+) Embeddings => OpenAI Embeddings
К In-Memory Vector Store подключить: 
(+) Document Loaders => PDF File

• Разделение данных на более мелкие фрагменты и преобразование их в векторное представление.
К PDF File подключить:
(+) Text Spliters => Recursive Character Text Spliter 
Здесь можно указать размер и нахлест чанков. Для увеличения точностит ответов нужно эксперементировать с этими параметрами. 


05:35 Загрузка данных в векторное хранилище

• Добавление узла "хранилище векторов" в проект.
• Подключение к источнику данных и выбор типа хранилища (например, "веб-скребок").

07:19 Использование векторного хранилища

• Подключение к векторному хранилищу и использование его для получения данных из источника.
• Использование "разделителя текста" для разделения данных на более мелкие фрагменты.

10:25 Загрузка данных в базу данных

• Загрузка данных в базу данных с помощью "зеленой кнопки" и "поиска API".
Справа, возле кнопки чата
• Получение конечной точки API для запуска скачка из пользовательских решений.

11:46 Использование веб-скребков для извлечения информации

• В видео демонстрируется использование веб-скребков для извлечения информации из документации по потоковой передаче.
• В примере используется веб-скребок Cheerio для получения информации с веб-сайта и добавления ее в векторное хранилище.

15:02 Добавление бессерверной базы данных Pinecone

• В видео объясняется, как добавить бессерверную базу данных Pinecone в проект.
• Для этого необходимо зарегистрироваться или войти в аккаунт Pinecone, создать индекс, добавить учетные данные и название индекса.
• После этого можно использовать Pinecone для хранения и обновления данных.

18:00 Советы по использованию поисковых запросов

• В видео даются советы по использованию поисковых запросов для получения информации из базы данных.
• Если необходимо просмотреть исходные документы, можно включить эту функцию в настройках.
• Также можно настроить системное приглашение для чат-бота, добавив информацию о компании и имени чат-бота.



Руководство по FlowiseAI #7 - Анализ потоков чата с помощью LangSmith

00:00 Отладка и мониторинг приложений LLM

• Видео обсуждает использование платформы Langsmith для детальной отладки и мониторинга приложений LLM.
• Langsmith позволяет отслеживать количество токенов, используемых приложением, и анализировать каждый шаг в рамках приложения.

01:44 Примеры использования Langsmith

• Видео демонстрирует использование Langsmith на примере простой цепочки LLM, анализатора выходных данных и цепочки разговоров с выделенной буферной памятью.
• Langsmith позволяет увидеть, как работает память в приложениях LLM, и как входные данные и ответы передаются между различными шагами в цепочке.

11:20 Использование Langsmith в Flowwise

• В видео рассказывается о том, как использовать Langsmith в Flowwise для анализа и обработки данных.
• В примере с чат-ботом, модель смогла ответить на вопрос, используя историю ввода.
• В другом примере, модель извлекает информацию из базы данных Pinecone, чтобы дать ответ на вопрос о языке длинных цепочек выражений.

12:10 Анализ документов и устранение неполадок

• В видео демонстрируется, как использовать Langsmith для анализа документов и устранения неполадок.
• В выводе можно увидеть информацию о документах, которые использовались в контексте, и их метаданные.
• Это может быть полезно для устранения проблем, связанных с устаревшими или проблемными документами, которые могут возвращать неверную информацию.






Создание личного помощника с помощью агентов (без кода) - Руководство по Flowise #8

00:00 Создание агента с искусственным интеллектом

• Обсуждение различий между сетями и агентами, где агенты могут использовать логику для выполнения задач.
• Создание нового потока общения в чате, добавление диалогового агента и модели чата.

03:59 Добавление инструментов к агенту

• Добавление калькулятора и инструмента поиска в Google для агента.
• Использование инструмента "langsmith" для отслеживания работы агента.

08:35 Создание уникальной цепочки llm для создания рецепта

• Создание цепочки llm для создания уникального рецепта и добавление ее в качестве инструмента к агенту.
• Добавление шаблона приглашения и ввода из окна чата для работы цепочки llm.

10:52 Использование агента для ответов на вопросы из базы знаний

• Демонстрация работы агента, который может отвечать на вопросы из базы знаний, обученной на бизнес-данных.

11:31 Добавление поиска в агент

• В видео обсуждается добавление поиска в агент с использованием инструмента поиска.
• Поиск может быть использован для получения информации из PDF-документов или из существующей базы знаний.

12:26 Примеры использования поиска

• В первом примере, агент использует поиск для получения информации о Tesla из PDF-документа.
• Во втором примере, агент использует поиск для получения информации из существующей базы знаний Pinecone.

13:52 Подключение векторного хранилища

• В видео объясняется, как подключить векторное хранилище к агенту.
• В примере используется векторное хранилище, созданное в предыдущем видео.

14:54 Тестирование поиска

• В видео демонстрируется, как использовать поиск для получения информации из PDF-документа.
• В другом примере, поиск используется для получения информации из базы знаний Pinecone.




Как Получить Доступ К Flowise Из ЛЮБОГО МЕСТА - Руководство По Flowise #9

00:00 Развертывание Flowwise в облаке

• Видео показывает, как развернуть Flowwise в облаке для доступа к потокам чата из любого места.
• Это также необходимо для интеграции чат-ботов Flowwise в веб-сайты и другие приложения.

01:51 Развертывание на Render

• Видео объясняет, как развернуть Flowwise на Render, используя GitHub.
• Для этого нужно создать копию Flowwise в своем пространстве имен и развернуть ее на Render.

05:09 Настройка переменных окружения

• Видео объясняет, как настроить переменные окружения для доступа к Flowwise.
• Важные переменные: имя пользователя и пароль Flowwise, версия узла, путь к базе данных и ключ API.

08:28 Обновление Flowwise при рендеринге

• Видео показывает, как обновить Flowwise при рендеринге, используя GitHub.
• Это позволяет получать новые обновления и использовать их в своем экземпляре Flowwise.






Добавление чат-ботов с искусственным интеллектом на веб-сайты - Flowise Tutorial #10

00:00 Введение в чат-боты

• Видео рассказывает о том, как добавить чат-бота с искусственным интеллектом на веб-сайт с помощью Flowwise AI.
• Чат-боты могут быть встроены в веб-сайты и интернет-магазины, и их можно настроить с помощью Flowwise.

01:35 Настройка внешнего вида чат-бота

• В видео показано, как изменить внешний вид чат-бота, включая цветовую схему и расположение окна чата.
• Для этого используется тематический объект, который можно настроить с помощью Flowwise.

02:47 Включение чат-бота в веб-сайт

• Видео демонстрирует, как добавить чат-бот на HTML-сайт и в приложение на JavaScript.
• Для этого используются различные варианты встраивания, включая React.

07:33 Настройка внешнего вида чат-бота в React

• Видео показывает, как настроить внешний вид чат-бота в приложении на JavaScript, используя Flowwise.
• Для этого используется тематический объект, который можно настроить с помощью Flowwise.

11:25 Использование атрибутов в чате

• В видео демонстрируется использование атрибутов на экране для внесения изменений в всплывающее окно чата.
• Можно изменить цвет кнопки, размер, положение, значок URL-адреса и другие параметры.

12:38 Удаление фирменного стиля

• Для удаления фирменного стиля можно изменить цвет текста на белый.
• Это самый простой способ, но есть и другие способы, которые требуют больше усилий.

13:24 Изменение настроек для ввода текста

• Можно изменить цвет фона сообщения бота, цвет текста, аватар и настройки для ввода текста.
• После внесения изменений, код автоматически корректируется, и можно скопировать его в буфер обмена.



Video GPT

https://youtu.be/kAyKOsm8L5Y?list=PL4HikwTaYE0H7wBxhvQqxYcKOkZ4O3zXh
### Подробный конспект по уроку "Creating Chatflows & LLM Chains - FlowiseAI Tutorial #2"

#### Введение
- В этом уроке мы создаем наш первый чат-флоу (chat flow) с использованием Flow-wise.
- Создаем новый чат-флоу, называем его "My First Chat Flow" и сохраняем.

#### Создание чат-флоу
- **API endpoint**: позволяет интегрировать наш чат-флоу с внешними приложениями.
  - Пример кода для встраивания на сайт, пример кода на Python и JavaScript.
  - Настройка API ключа для защиты endpoint.
  - Настройка ограничений и сообщений при превышении лимита.
- **Настройки**: просмотр прошлых разговоров, дублирование, загрузка, экспорт и удаление чат-флоу.
  - Интеграция инструментов для анализа, таких как Langsmith.
- **Интерфейс**: добавление узлов (nodes), взаимодействие с чат-флоу, управление масштабом и блокировкой узлов.

#### Добавление узлов
- Все чат-флоу должны содержать как минимум одного агента (agent) или одну цепочку (chain).
- Начнем с добавления цепочки LLM Chain (Large Language Model Chain).
  - В интерфейсе нажмите на плюсик (+), выберите "Chains" и добавьте "Conversational Retrieval QA Chain".
  (+) Chains => Conversational Retrieval QA Chain

#### Подключение Chat Models и In-Memory Vector Store
1. **Chat Models**: подключаем узел ChatOpenAI.
   - В интерфейсе нажмите на плюсик (+), выберите "Chat Models" и добавьте "ChatOpenAI".
   (+) Chat Models => ChatOpenAI 
   - Создаем новые учетные данные (credentials) для OpenAI API (ключ).
   - Просмотр и повторное использование кредов через панель управления.
   - Настройка модели OpenAI: выбор из трех моделей (GPT-3.5, GPT-4), настройка температуры и других параметров.
   
2. **In-Memory Vector Store**: добавляем узел векторного хранилища (Vector Store).
   - В интерфейсе нажмите на плюсик (+), выберите "Vector Stores" и добавьте "In-Memory Vector Store".
   (+) Vector Stores => In-Memory Vector Store
   - Подключаем узел OpenAI к цепочке LLM Chain, указываем креды для API.
   - Убедимся, что узел правильно подключен.

#### Настройка Embeddings и Document Loaders
1. **Embeddings**: подключаем OpenAI Embeddings к In-Memory Vector Store.
   - В интерфейсе нажмите на плюсик (+), выберите "Embeddings" и добавьте "OpenAI Embeddings".
   (+) Embeddings => OpenAI Embeddings
   - Настройка параметров для эффективного извлечения данных.

2. **Document Loaders**: подключаем PDF File к In-Memory Vector Store.
   - В интерфейсе нажмите на плюсик (+), выберите "Document Loaders" и добавьте "PDF File".
   (+) Document Loaders => PDF File

#### Промпты и шаблоны
- Добавление шаблона промпта (Prompt Template).
  - В интерфейсе нажмите на плюсик (+), выберите "Prompts" и добавьте "Prompt Template".
  (+) Prompts => Prompt Template
  - Пример: "tell me a joke about horses".
  - Сохранение и тестирование промпта.
  - Настройка динамических значений (variables) для промпта.
  - Инъекция пользовательского ввода в промпт через настройку переменных.
  - Связывание переменной `subject` с вводом из чат-бокса (chat box).

#### Тестирование и демонстрация
- Тестирование чат-флоу через чат-интерфейс.
  - Ввод различных запросов и получение ответов.
  - Динамическая настройка и тестирование промпта с различными темами (например, "cat" или "dog").

Этот урок охватывает основные шаги создания и настройки чат-флоу с использованием цепочек LLM и интеграцией моделей OpenAI.



https://youtu.be/yLfiNnK4NOM?list=PL4HikwTaYE0H7wBxhvQqxYcKOkZ4O3zXh
### Подробный конспект по уроку "Combining Multiple Chains (Prompt Chaining) - FlowiseAI Tutorial #3"

#### Введение
- В этом уроке мы научимся объединять несколько цепочек (chains) в одном чат-флоу, чтобы взять выходные данные из одной цепочки и использовать их в качестве входных данных для другой.
- Цель: создать цепочку с шеф-поваром (chef), который генерирует рецепт, и критиком (critic), который пишет отзыв на этот рецепт.

#### Создание первой цепочки (Chef Chain)
- Добавляем первую цепочку, которая будет генерировать рецепт.
- **Добавление цепочки**:
  - В интерфейсе нажмите на плюсик (+), выберите "Chains" и добавьте "Conversational Retrieval QA Chain".
  (+) Chains => Conversational Retrieval QA Chain
- **Настройка шаблона промпта для Chef Chain**:
  - Откройте окно шаблона промпта и введите текст: "You are an experienced chef. Create a unique recipe using the main ingredient {ingredient}".
  - Сохраните шаблон промпта.
- **Связывание переменных**:
  - Свяжите переменную `ingredient` с вводом из чат-бокса (chat box).
  - Удалите существующие ключевые значения и добавьте новое ключевое значение `ingredient`.
  - Настройка завершена, сохраните чат-флоу и тестируйте вводом основного ингредиента (например, курица).

#### Создание второй цепочки (Critic Chain)
- Создаем цепочку критика, которая будет писать отзыв на рецепт.
- **Добавление цепочки**:
  - В интерфейсе нажмите на плюсик (+), выберите "Chains" и добавьте "Conversational Retrieval QA Chain".
  (+) Chains => Conversational Retrieval QA Chain
- **Добавление узла цепочки LLM**:
  - В интерфейсе нажмите на плюсик (+), выберите "LLMs" и добавьте "OpenAI".
  (+) LLMs => OpenAI
  - Подключите узел OpenAI к цепочке.
  - Установите креды OpenAI.
- **Настройка шаблона промпта для Critic Chain**:
  - Откройте окно шаблона промпта и введите текст: "You are a harsh and rude food critic. Write a review about the following recipe: {recipe}".
  - Сохраните шаблон промпта.
- **Связывание переменных**:
  - Свяжите выходные данные первой цепочки (Chef Chain) с переменной `recipe` во второй цепочке (Critic Chain).
  - Настройка завершена, сохраните чат-флоу и тестируйте вводом основного ингредиента (например, картофель).

#### Замена модели и тестирование
- Заменяем используемую модель на более мощную:
  - Удалите узел LLM и добавьте узел ChatOpenAI.
  - В интерфейсе нажмите на плюсик (+), выберите "Chat Models" и добавьте "ChatOpenAI".
  (+) Chat Models => ChatOpenAI
  - Установите модель GPT-3.5 Turbo.
  - Установите температуру модели на 0.7 и сохраните настройки.
- **Тестирование чат-флоу**:
  - Очищаем предыдущий чат и вводим новый ингредиент (например, картофель).
  - Проверяем качество выходных данных, убедившись в их улучшении.
  - В консоли можно просмотреть промежуточные результаты (например, сгенерированный рецепт шеф-повара и отзыв критика).

### Заключение
- В этом уроке мы научились объединять несколько цепочек в одном чат-флоу.
- Использование более мощной модели (GPT-3.5 Turbo) значительно улучшает качество выходных данных.
- Возможность просмотра промежуточных данных через консоль помогает в отладке и улучшении чат-флоу.




https://youtu.be/bT308854-Qw?list=PL4HikwTaYE0H7wBxhvQqxYcKOkZ4O3zXh
### Подробный конспект по уроку "Output Parsers & IfElse Function - FlowiseAI Tutorial #4"

#### Введение
- В этом уроке рассматривается использование выходных парсеров (Output Parsers) и функции IfElse в Flowwise.
- Цель: научиться контролировать типы выходных данных моделей и условно вызывать цепочки (chains) на основе этих данных.

#### Настройка основной цепочки
- **Добавление узлов цепочки**:
  - В интерфейсе нажмите на плюсик (+) и выберите "Chains", затем добавьте "Conversational Retrieval QA Chain".
  (+) Chains => Conversational Retrieval QA Chain

#### Подключение Chat Models и In-Memory Vector Store
1. **Chat Models**: подключаем узел ChatOpenAI.
   - В интерфейсе нажмите на плюсик (+), выберите "Chat Models" и добавьте "ChatOpenAI".
   (+) Chat Models => ChatOpenAI 
   - Настройте модель OpenAI, выбрав "GPT-3.5 Turbo", и установите температуру на 0.7.
   - Сохраните настройки.
   
2. **In-Memory Vector Store**: добавляем узел векторного хранилища (Vector Store).
   - В интерфейсе нажмите на плюсик (+), выберите "Vector Stores" и добавьте "In-Memory Vector Store".
   (+) Vector Stores => In-Memory Vector Store

#### Настройка Embeddings и Document Loaders
1. **Embeddings**: подключаем OpenAI Embeddings к In-Memory Vector Store.
   - В интерфейсе нажмите на плюсик (+), выберите "Embeddings" и добавьте "OpenAI Embeddings".
   (+) Embeddings => OpenAI Embeddings

2. **Document Loaders**: подключаем PDF File к In-Memory Vector Store.
   - В интерфейсе нажмите на плюсик (+), выберите "Document Loaders" и добавьте "PDF File".
   (+) Document Loaders => PDF File

#### Добавление выходных парсеров
1. **Structured Output Parser**: для обеспечения того, что модель возвращает данные в определенном формате.
   - В интерфейсе нажмите на плюсик (+), выберите "Output Parsers" и добавьте "Structured Output Parser".
   - Настройте выходной парсер, задав параметр `sentiment` типа `boolean` с описанием "sentence is true or false".
   
2. **Пример использования**: Извлечение информации из предложения.
   - Измените шаблон промпта на "Extract information from the following sentence".
   - Настройте переменные в шаблоне, добавив `name`, `age` и `spouse`.
   - Тестируйте, вводя предложения, такие как "Max is 30 years old and married to Angie".

#### Условный вызов цепочек с IfElse
1. **Настройка цепочек для положительных и отрицательных отзывов**:
   - Создайте две цепочки: одну для положительных отзывов, другую для отрицательных.
   - **Положительная цепочка**:
     - Добавьте узел ChatOpenAI и настройте модель OpenAI.
     - Добавьте шаблон промпта: "You are a customer support assistant. First, thank the client for the review, and then ask if they would like to post a review to our website. Also summarize the review."
   - **Отрицательная цепочка**:
     - Добавьте узел ChatOpenAI и настройте модель OpenAI.
     - Добавьте шаблон промпта: "You are a customer support assistant that deals with negative reviews. Write an apology for the following review, and ask the user if they would like to be contacted by a customer service rep."
     
2. **Добавление IfElse узла**:
   - В интерфейсе нажмите на плюсик (+), выберите "Utilities" и добавьте "IfElse Function".
   - Настройте условие, чтобы положительные отзывы направлялись в положительную цепочку, а отрицательные - в отрицательную.
   - Свяжите выходные данные основной цепочки с IfElse функцией.

#### Тестирование и демонстрация
- Тестируйте чат-флоу, вводя положительные и отрицательные отзывы, чтобы проверить правильность работы цепочек.
- Пример положительного отзыва: "The food was awesome".
- Пример отрицательного отзыва: "The waiter was rude and the food was cold".

### Заключение
- В этом уроке мы научились использовать выходные парсеры и условные вызовы цепочек в Flowwise.
- Эти инструменты позволяют более точно контролировать выходные данные моделей и условно вызывать различные цепочки на основе полученной информации.



https://youtu.be/xJ3iohxHIGo?list=PL4HikwTaYE0H7wBxhvQqxYcKOkZ4O3zXh
### Подробный конспект по уроку "Building Chatbots with Long-Term Memory - FlowiseAI Tutorial #5"

#### Введение
- В этом уроке мы создаем чат-бота с использованием цепочек разговоров (Conversation Chains) и долгосрочной памяти.
- Цель: создать чат-бота, который может запоминать и вспоминать предыдущие разговоры, используя Flowwise.

#### Создание чат-флоу
- Создаем новый чат-флоу и называем его "My First Chat Flow". Сохраняем.
- В предыдущих видео рассматривались LLM цепочки, которые используются для одноразовых запросов (например, генерация рецепта или шутки).

#### Добавление узлов
- Переходим к добавлению узлов:
  - В интерфейсе нажмите на плюсик (+), выберите "Chains" и добавьте "Conversational Retrieval QA Chain".
  (+) Chains => Conversational Retrieval QA Chain

#### Подключение Chat Models и In-Memory Vector Store
1. **Chat Models**: подключаем узел ChatOpenAI.
   - В интерфейсе нажмите на плюсик (+), выберите "Chat Models" и добавьте "ChatOpenAI".
   (+) Chat Models => ChatOpenAI 
   - Настройте модель OpenAI, выбрав "GPT-3.5 Turbo", и установите температуру на 0.7.
   - Сохраните настройки.

#### Добавление памяти (Memory)
- Переходим к добавлению памяти:
  - В интерфейсе нажмите на плюсик (+), выберите "Memory" и добавьте "Buffer Memory".
  (+) Memory => Buffer Memory
  - Подключаем узел Buffer Memory к цепочке.

#### Тестирование и улучшение чат-бота
- Сохраняем чат-флоу и открываем чат для тестирования.
  - Пример: "Hello", "My name is Leon", "What is my name?".
  - Проверяем работу памяти: чат-бот должен запомнить и ответить на вопросы, используя информацию из предыдущих сообщений.
- Просмотр прошлых разговоров:
  - Переходим в "Settings" и нажимаем на "View Messages" для просмотра истории разговоров.

#### Настройка шаблонов промптов (Prompt Templates)
- Переходим к добавлению шаблонов промптов:
  - В интерфейсе нажмите на плюсик (+), выберите "Prompts" и добавьте "Chat Prompt Template".
  (+) Prompts => Chat Prompt Template
  - Подключаем шаблон к цепочке.
  - Настройка системного сообщения в дополнительных параметрах:
    - Пример: "Your name is Hope. Rhyme every sentence".
  - Настройка переменных для ввода пользователя (например, `input`).

#### Модерация ввода (Input Moderation)
- Добавление модерации ввода:
  - В интерфейсе нажмите на плюсик (+), выберите "Moderation" и добавьте "Simple Prompt Moderation".
  (+) Moderation => Simple Prompt Moderation
  - Подключаем узел модерации к цепочке.
  - Настройка цензуры определенных слов или фраз (например, "frogs are ugly").

#### Долгосрочная память (Long-Term Memory)
- Замена Buffer Memory на долгосрочную память:
  - В интерфейсе нажмите на плюсик (+), выберите "Memory" и добавьте "Upstash Redis Memory".
  (+) Memory => Upstash Redis Memory
  - Подключаем узел к цепочке.
  - Настройка Upstash Redis:
    - Создаем новые креды, добавляем REST Token и URL.
    - Указываем уникальный идентификатор сессии (например, chat1).
- Тестирование долгосрочной памяти:
  - Пример: "What is your name?", "My name is Leon", "What is my name?".

### Заключение
- В этом уроке мы научились создавать чат-бота с использованием Flowwise, который может запоминать и вспоминать предыдущие разговоры.
- Эти инструменты позволяют улучшить взаимодействие с пользователями и создать более персонализированные и интерактивные чат-боты.




### Подробный конспект видео "Chatting With Your Own Data! Chat, Predict, & Analyze - FlowiseAI Tutorial #6"

#### Введение в RAG
- **RAG (Retrieval Augmented Generation)**: Это метод, который позволяет ИИ моделям получать информацию из внешних источников данных для улучшения точности ответов.
- Ограничения моделей ИИ: Они могут отвечать только на вопросы, основанные на данных, на которых они были обучены. Например, ChatGPT не знает о текущих событиях или специальных инструкциях по Flowwise.

#### Создание цепочки Retrieval
- **Концепция**: Подключение чат-бота к источнику данных (например, PDF-документу) и использование векторного хранилища для хранения и извлечения информации.
- **Шаги**:
  1. **Загрузка данных**: Из источника данных в приложение.
  2. **Разделение текста**: Разбиение данных на небольшие фрагменты (чанки) для уменьшения использования токенов.
  3. **Создание векторов**: Преобразование текстовых фрагментов в векторные представления.
  4. **Хранение в векторном хранилище**: Сохранение векторов в базе данных.
  5. **Извлечение**: Когда пользователь задает вопрос, чат-бот извлекает наиболее релевантные документы из векторного хранилища и добавляет их в контекст запроса.

#### Практическое создание чат-бота
- **Шаг 1: Добавление цепочки**: В Flowwise создаем новый проект и добавляем цепочку "Conversational Retrieval QA Chain".
  (+) Chains => Conversational Retrieval QA Chain 

- **Шаг 2: Добавление модели чата**: Добавляем модель "ChatOpenAI" и настраиваем параметры.
  (+) Chat Models => ChatOpenAI 

- **Шаг 3: Добавление векторного хранилища**: Используем In-Memory Vector Store.
  (+) Vector Stores => In-Memory Vector Store

- **Шаг 4: Подключение Embeddings**: Добавляем "OpenAI Embeddings" для преобразования данных в векторные представления.
  (+) Embeddings => OpenAI Embeddings

- **Шаг 5: Загрузчики документов**: Подключаем PDF-файл через Document Loaders.
  (+) Document Loaders => PDF File

#### Работа с текстом и запросами
- **Разделение текста**: Используем "Recursive Character Text Splitter" для разделения текста на фрагменты по 1000 символов с перекрытием в 50 символов.
- **Загрузка PDF-файлов**: Загружаем финансовый отчет и проверяем работу чат-бота с вопросами к этому PDF-файлу.
- **Скрепинг веб-страниц**: Используем Cheerio Web Scraper для извлечения данных с веб-страниц, например, с документации Flowwise.

#### Подключение Pinecone Serverless Database
- **Проблема**: In-Memory Vector Store теряет данные при перезапуске сервера.
- **Решение**: Использование Pinecone Serverless Database для постоянного хранения данных.
- **Шаги**:
  1. Создание индекса в Pinecone и получение API-ключа.
  2. Подключение Pinecone к Flowwise через настройки.

#### Дополнительные функции
- **Добавление источников данных**: Включение источников данных в ответы чат-бота.
- **Параметры системы**: Настройка системных сообщений и параметров для изменения поведения чат-бота.

#### Заключение
- В видео объясняется создание чат-бота, который использует Retrieval Augmented Generation для ответов на вопросы из собственных источников данных. Показаны основные шаги и практические примеры использования Flowwise и Pinecone.

**Полезные ссылки**:
- Pinecone: [https://www.pinecone.io/](https://www.pinecone.io/)
- Discord: [https://discord.gg/VwHZzbNawh](https://discord.gg/VwHZzbNawh)
- Cognaitiv AI: [https://www.cognaitiv.ai](https://www.cognaitiv.ai)

**Таймкоды**:
- 00:00 - Введение в RAG
- 00:47 - Retrieval Augmented Generation
- 02:58 - Диаграмма Retrieval
- 04:09 - Создание Retrieval Chain
- 05:17 - Добавление Buffer Vector Store
- 06:03 - Добавление Embeddings
- 06:28 - Добавление Document Loaders
- 07:07 - Загрузчик PDF документов
- 07:32 - Причина разделения на части
- 09:03 - Добавление Text Splitter
- 10:28 - Загрузка данных
- 11:49 - Cheerio Web Scraper
- 14:49 - Добавление Pinecone Serverless
- 18:03 - Возврат исходных документов
- 18:25 - Только Inject Flow
- 19:06 - Prompting / System Message
